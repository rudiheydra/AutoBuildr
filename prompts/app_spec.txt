<project_specification>
  <project_name>AutoBuildr</project_name>

  <overview>
    AutoBuildr is a declarative, spec-driven agentic build system that provides a dynamic,
    agent-agnostic platform. Each task is compiled at runtime into a structured AgentSpec. Instead of
    predefining agents in code, each task is compiled at runtime into a structured AgentSpec
    that defines the agent's objective, constraints, tools, acceptance criteria, and execution
    budget. A lightweight, agent-agnostic harness executes these specs, manages state, enforces
    verification gates, and persists all artifacts for traceability.
  </overview>

  <technology_stack>
    <frontend>
      <framework>React with Vite (existing)</framework>
      <styling>Tailwind CSS (existing)</styling>
      <state_management>React hooks, context, WebSocket (existing)</state_management>
      <port>5173 (dev) / 8888 (production)</port>
    </frontend>
    <backend>
      <runtime>Python with FastAPI (existing)</runtime>
      <database>SQLite with SQLAlchemy (existing)</database>
      <ai_framework>Claude SDK, DSPy (for spec compilation)</ai_framework>
      <port>8888</port>
    </backend>
    <communication>
      <api>RESTful endpoints + WebSocket (existing)</api>
      <mcp>MCP server for agent tools (existing)</mcp>
    </communication>
  </technology_stack>

  <prerequisites>
    <environment_setup>
      - Python 3.11+ with uv package manager
      - Node.js 18+ for frontend
      - Anthropic API key (ANTHROPIC_API_KEY)
      - DSPy library for spec compilation
      - Existing AutoBuildr infrastructure preserved
    </environment_setup>
  </prerequisites>

  <feature_count>85</feature_count>

  <architectural_principles>
    <principle name="Agent-Agnostic Kernel">
      The HarnessKernel executes any AgentSpec without knowledge of task semantics.
      It only understands: objective, tools, budget, acceptance criteria.
    </principle>
    <principle name="Flat Execution">
      No runtime sub-agent spawning in v1. The kernel may create new specs on failure
      (e.g., debug task), but agents do not spawn child specs during execution.
    </principle>
    <principle name="Immutable Audit Trail">
      Every agent action is recorded as an immutable AgentEvent. Enables full
      reproducibility, debugging, and acceptance verification.
    </principle>
    <principle name="Least-Privilege Tools">
      ToolPolicy defines allowed/forbidden tools per spec. Agents only get
      the capabilities they need, nothing more.
    </principle>
    <principle name="Deterministic Verification">
      v1 uses only deterministic validators (test_pass, file_exists, forbidden_patterns).
      No LLM-as-judge until later phases.
    </principle>
    <principle name="Backward Compatibility">
      Existing hard-coded agents coexist via migration flag. Legacy path works
      while new kernel proves stable.
    </principle>
  </architectural_principles>

  <security_and_access_control>
    <tool_policy>
      <allowed_tools>Whitelist of permitted tools (None = all allowed)</allowed_tools>
      <forbidden_patterns>Regex patterns for dangerous operations (e.g., "rm -rf /")</forbidden_patterns>
      <allowed_directories>Sandbox paths agent can access</allowed_directories>
    </tool_policy>
    <execution_budget>
      <max_turns>Per-agent turn limit to prevent runaway execution</max_turns>
      <timeout_seconds>Wall-clock timeout for entire run</timeout_seconds>
    </execution_budget>
    <artifact_security>
      <content_addressable>Large artifacts stored by SHA256 hash</content_addressable>
      <size_threshold>4KB cutoff for inline vs file-based storage</size_threshold>
    </artifact_security>
  </security_and_access_control>

  <core_features>
    <phase_0_kernel_wiring>
      <harness_kernel_core>
        - HarnessKernel.execute(spec) accepts AgentSpec and returns AgentRun
        - Create AgentRun record with status=running at execution start
        - Build system prompt from spec.objective and spec.context
        - Execute via Claude SDK with configured tools
        - Enforce max_turns budget during execution loop
        - Enforce timeout_seconds wall-clock limit
        - Handle graceful termination on budget exhaustion
        - Return finalized AgentRun with verdict
      </harness_kernel_core>

      <agent_run_lifecycle>
        - AgentRun status transitions: pending -> running -> completed/failed/timeout
        - Track turns_used counter during execution
        - Track tokens_in and tokens_out for cost visibility
        - Record started_at timestamp at run start
        - Record completed_at timestamp at run end
        - Store final_verdict from acceptance evaluation
      </agent_run_lifecycle>

      <agent_event_recording>
        - Record "started" event when run begins
        - Record "tool_call" event for each tool invocation (tool name, arguments)
        - Record "tool_result" event for each tool response
        - Record "turn_complete" event after each turn
        - Record "acceptance_check" event when validators run
        - Record "completed" event on successful finish
        - Record "failed" event on error with error message
        - Record "timeout" event on budget exhaustion
        - Enforce 4KB payload cap (larger content -> artifact reference)
        - Maintain sequential ordering via sequence number
      </agent_event_recording>

      <acceptance_spec_validators>
        - Validator interface with evaluate(run, context) -> ValidatorResult
        - test_pass validator: run command, check exit code
        - file_exists validator: verify file path exists
        - forbidden_patterns validator: ensure output doesn't contain patterns
        - lint_clean validator (optional): run linter, check for errors
        - Gate mode all_pass: all validators must succeed
        - Gate mode any_pass: at least one validator must succeed
      </acceptance_spec_validators>

      <artifact_storage>
        - Inline storage for content <= 4KB
        - File-based storage for content > 4KB
        - SHA256 content hash for all artifacts
        - artifact_type enum: file_change, test_result, log, metric, snapshot
        - Link artifacts to AgentRun via run_id
      </artifact_storage>

      <static_spec_adapter>
        - Wrap existing initializer agent as static AgentSpec
        - Wrap existing coding agent as static AgentSpec
        - Wrap existing testing agent as static AgentSpec
        - Load prompts from templates as spec.objective
        - Migration flag to choose kernel vs legacy execution
      </static_spec_adapter>
    </phase_0_kernel_wiring>

    <phase_1_dspy_specbuilder>
      <dspy_signatures>
        - SpecGenerationSignature for task -> AgentSpec compilation
        - Input: task description, task_type, project_context
        - Output: objective, context, tool_policy, budget, acceptance_spec
        - Chain-of-thought reasoning for spec decisions
      </dspy_signatures>

      <template_registry>
        - Load skill templates from prompts/ directory
        - Template selection based on task_type
        - Template variable interpolation
        - Cache compiled templates for performance
      </template_registry>

      <feature_to_spec_compiler>
        - Convert Feature record to AgentSpec
        - Extract objective from feature description
        - Derive tool_policy from feature category
        - Set acceptance_spec based on feature steps
        - Link via source_feature_id for traceability
        - Generate unique spec name from feature
      </feature_to_spec_compiler>

      <display_derivation>
        - Generate display_name from objective summary
        - Select icon based on task_type
        - Assign mascot name from existing pool
      </display_derivation>

      <migration_flag_logic>
        - AUTOBUILDR_USE_KERNEL environment variable
        - Default: false (use legacy agents)
        - When true: compile Feature -> AgentSpec -> HarnessKernel
        - Graceful fallback on kernel errors
      </migration_flag_logic>
    </phase_1_dspy_specbuilder>

    <phase_2_toolprovider_expansion>
      <tool_policy_enforcement>
        - Filter tools based on spec.tool_policy.allowed_tools
        - Block tools in spec.tool_policy.forbidden_tools
        - Validate tool arguments against forbidden_patterns
        - Restrict file operations to allowed_directories
        - Log policy violations as events
      </tool_policy_enforcement>

      <external_provider_integration>
        - ToolProvider interface for external tool sources
        - Cowork integration (deferred to Phase 2+)
        - Composio integration (deferred to Phase 2+)
        - Provider registration and discovery
        - Tool capability negotiation
        - OAuth/credential management (deferred)
      </external_provider_integration>

      <sandbox_restrictions>
        - Resolve allowed_directories to absolute paths
        - Block path traversal attempts
        - Validate symlink targets
        - Audit directory access in events
      </sandbox_restrictions>
    </phase_2_toolprovider_expansion>

    <phase_3_ui_dynamic_cards>
      <websocket_event_extensions>
        - agent_spec_created message when spec registered
        - agent_run_started message when run begins
        - agent_event_logged message for significant events
        - agent_acceptance_update message for validator results
      </websocket_event_extensions>

      <dynamic_agent_card_component>
        - DynamicAgentCard component from AgentSpec + AgentRun
        - Display spec.display_name and spec.icon
        - Show run status with color coding
        - Display turns_used / max_turns progress
        - Show current state (thinking/working/testing/etc)
      </dynamic_agent_card_component>

      <run_inspector>
        - Timeline view of AgentEvents for a run
        - Expandable event details
        - Artifact preview and download
        - Filter events by type
      </run_inspector>

      <acceptance_progress_ui>
        - Show validator names and status
        - Pass/fail indicators per validator
        - Overall gate status display
      </acceptance_progress_ui>
    </phase_3_ui_dynamic_cards>
  </core_features>

  <database_schema>
    <tables>
      <agent_specs>
        - id (UUID, PRIMARY KEY)
        - name (VARCHAR, unique machine-readable identifier)
        - display_name (VARCHAR, human-readable)
        - icon (VARCHAR, emoji or icon name)
        - objective (TEXT, what agent should accomplish)
        - task_type (ENUM: coding|testing|refactoring|documentation|audit|custom)
        - context (JSON, task-specific structured data)
        - tool_policy (JSON, allowed/forbidden tools and patterns)
        - max_turns (INTEGER, execution budget)
        - timeout_seconds (INTEGER, wall-clock limit)
        - parent_spec_id (UUID, FK -> agent_specs.id, nullable)
        - source_feature_id (INTEGER, FK -> features.id, nullable)
        - priority (INTEGER)
        - tags (JSON array)
        - created_at (TIMESTAMP)
      </agent_specs>

      <acceptance_specs>
        - id (UUID, PRIMARY KEY)
        - agent_spec_id (UUID, FK -> agent_specs.id, UNIQUE)
        - validators (JSON array of validator objects)
        - gate_mode (ENUM: all_pass|any_pass|weighted)
        - min_score (FLOAT, nullable, for weighted mode)
        - retry_policy (ENUM: none|fixed|exponential)
        - max_retries (INTEGER)
        - fallback_spec_id (UUID, FK -> agent_specs.id, nullable)
      </acceptance_specs>

      <agent_runs>
        - id (UUID, PRIMARY KEY)
        - agent_spec_id (UUID, FK -> agent_specs.id)
        - status (ENUM: pending|running|paused|completed|failed|timeout)
        - started_at (TIMESTAMP)
        - completed_at (TIMESTAMP, nullable)
        - turns_used (INTEGER)
        - tokens_in (INTEGER)
        - tokens_out (INTEGER)
        - final_verdict (ENUM: passed|failed|error, nullable)
        - acceptance_results (JSON, per-validator results)
        - error (TEXT, nullable)
        - retry_count (INTEGER)
      </agent_runs>

      <artifacts>
        - id (UUID, PRIMARY KEY)
        - run_id (UUID, FK -> agent_runs.id)
        - artifact_type (ENUM: file_change|test_result|log|metric|snapshot)
        - content_ref (VARCHAR, file path for large content)
        - content_inline (TEXT, for small content <= 4KB)
        - content_hash (VARCHAR, SHA256)
        - size_bytes (INTEGER)
        - metadata (JSON)
        - created_at (TIMESTAMP)
      </artifacts>

      <agent_events>
        - id (INTEGER, PRIMARY KEY, sequential)
        - run_id (UUID, FK -> agent_runs.id)
        - sequence (INTEGER, ordering within run)
        - event_type (ENUM: started|tool_call|tool_result|turn_complete|acceptance_check|completed|failed|paused|resumed|timeout)
        - timestamp (TIMESTAMP)
        - payload (JSON, capped at 4KB)
        - artifact_ref (UUID, FK -> artifacts.id, nullable)
        - tool_name (VARCHAR, nullable, denormalized for queries)
      </agent_events>

      <features>
        - (existing table, unchanged)
        - id, priority, category, name, description, steps
        - passes, in_progress, dependencies
        - Linked to AgentSpec via agent_specs.source_feature_id
      </features>
    </tables>

    <indexes>
      - agent_runs(agent_spec_id, status) for finding runs by spec
      - agent_events(run_id, sequence) for ordered event retrieval
      - agent_events(run_id, event_type) for filtering by type
      - artifacts(run_id) for finding run artifacts
      - artifacts(content_hash) for deduplication
    </indexes>
  </database_schema>

  <api_endpoints_summary>
    <agent_specs>
      - POST /api/agent-specs (create new spec)
      - GET /api/agent-specs (list specs with filters)
      - GET /api/agent-specs/:id (get single spec)
      - PUT /api/agent-specs/:id (update spec)
      - DELETE /api/agent-specs/:id (delete spec)
      - POST /api/agent-specs/:id/execute (trigger execution via kernel)
    </agent_specs>

    <agent_runs>
      - GET /api/agent-runs (list runs with filters)
      - GET /api/agent-runs/:id (get run details)
      - GET /api/agent-runs/:id/events (get run events)
      - GET /api/agent-runs/:id/artifacts (get run artifacts)
      - POST /api/agent-runs/:id/pause (pause running agent)
      - POST /api/agent-runs/:id/resume (resume paused agent)
      - POST /api/agent-runs/:id/cancel (cancel running agent)
    </agent_runs>

    <artifacts>
      - GET /api/artifacts/:id (get artifact metadata)
      - GET /api/artifacts/:id/content (download artifact content)
    </artifacts>

    <spec_builder>
      - POST /api/spec-builder/compile (compile task -> AgentSpec via DSPy)
      - GET /api/spec-builder/templates (list available templates)
    </spec_builder>

    <existing_endpoints>
      - (preserve all existing /api/projects, /api/features, /api/agent endpoints)
    </existing_endpoints>
  </api_endpoints_summary>

  <ui_layout>
    <main_structure>
      Extend existing Kanban UI with:
      - Dynamic agent cards derived from AgentSpec + AgentRun
      - Run inspector panel for event timeline
      - Acceptance progress indicators on cards
    </main_structure>

    <agent_card_extensions>
      - Display spec.display_name instead of hard-coded names
      - Show spec.icon dynamically
      - Progress bar for turns_used / max_turns
      - Validator status indicators
      - Link to run inspector
    </agent_card_extensions>

    <run_inspector_panel>
      - Slide-out panel from agent card click
      - Event timeline with expandable details
      - Artifact list with preview/download
      - Acceptance results summary
      - Error details if failed
    </run_inspector_panel>
  </ui_layout>

  <implementation_steps>
    <step number="0">
      <title>Phase 0: Kernel Wiring</title>
      <tasks>
        - Step A: Implement HarnessKernel.execute(spec) core loop
        - Create AgentRun on start, record events, run validators, finalize
        - Step B: Create StaticSpecAdapter for initializer/coding/testing
        - Prove kernel works with legacy agents as specs
        - Step C: Integration tests with mock Claude session
        - Validate event ordering, acceptance gates, artifact references
      </tasks>
    </step>

    <step number="1">
      <title>Phase 1: DSPy SpecBuilder</title>
      <tasks>
        - Implement DSPy signatures for spec generation
        - Build template registry with loading and interpolation
        - Create Feature-to-AgentSpec compiler
        - Add display property derivation
        - Implement migration flag logic
      </tasks>
    </step>

    <step number="2">
      <title>Phase 2: ToolProvider Expansion</title>
      <tasks>
        - Implement ToolPolicy enforcement in kernel
        - Add directory sandboxing
        - Create ToolProvider interface
        - Defer Cowork/Composio integration to later
      </tasks>
    </step>

    <step number="3">
      <title>Phase 3: UI Dynamic Cards</title>
      <tasks>
        - Extend WebSocket with spec/run events
        - Build DynamicAgentCard component
        - Create Run Inspector panel
        - Add acceptance progress UI
      </tasks>
    </step>
  </implementation_steps>

  <success_criteria>
    <functionality>
      - HarnessKernel executes any AgentSpec without task-specific code
      - All agent actions recorded as immutable events
      - Acceptance gates block false victories
      - Legacy agents work through StaticSpecAdapter
      - DSPy generates valid specs from feature descriptions
    </functionality>

    <correctness>
      - Events emitted in correct order
      - Artifacts stored with correct hashes
      - Budget enforcement terminates runaway agents
      - Validators produce deterministic results
    </correctness>

    <auditability>
      - Complete execution trace for any run
      - Artifacts retrievable by hash
      - Run can be replayed from event log
      - Clear lineage from Feature -> AgentSpec -> AgentRun
    </auditability>

    <extensibility>
      - New task types require only template + acceptance spec
      - ToolProviders pluggable without kernel changes
      - UI adapts to any AgentSpec structure
      - No hard-coded agent semantics in kernel
    </extensibility>

    <backward_compatibility>
      - Existing hard-coded agents continue working
      - Migration flag allows gradual transition
      - Feature table unchanged
      - All existing API endpoints preserved
    </backward_compatibility>
  </success_criteria>
</project_specification>

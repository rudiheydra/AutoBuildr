"""
Octo Service - Agent Generator
==============================

Octo is a DSPy-based service that generates AgentSpecs from structured request payloads.
It receives OctoRequestPayload from Maestro and returns one or more validated AgentSpecs.

Feature #176: Maestro delegates to Octo for agent generation
Feature #182: Octo DSPy signature for AgentSpec generation
Feature #183: Octo processes OctoRequestPayload and returns AgentSpecs
Feature #184: Octo generates TestContract alongside AgentSpec when applicable
Feature #185: Octo DSPy module with constraint satisfaction
Feature #187: Octo selects appropriate model for each agent
Feature #188: Octo outputs are strictly typed and schema-validated

This module provides:
- OctoRequestPayload: Structured input containing project context, required capabilities, and constraints
- OctoResponse: Response containing generated AgentSpecs and any errors
- TestContract: Structured test specification for testable agents
- Octo: Service class that invokes DSPy pipeline to generate AgentSpecs
- Model selection: Automatic selection of Claude model based on agent complexity
- Constraint validation: Ensures specs meet tool, model, and sandbox constraints (Feature #185)

Usage:
    from api.octo import Octo, OctoRequestPayload

    # Create Octo service
    octo = Octo(api_key="sk-...")

    # Build request payload with constraints
    payload = OctoRequestPayload(
        project_context={"name": "MyApp", "tech_stack": ["React", "Python"]},
        required_capabilities=["ui_testing", "api_testing"],
        existing_agents=["coder", "test-runner"],
        constraints={
            "max_agents": 3,
            "max_turns_limit": 100,  # Budget constraint
            "model": "sonnet",       # Model constraint
        }
    )

    # Generate AgentSpecs (constraint validation happens automatically)
    response = octo.generate_specs(payload)
    if response.success:
        for spec in response.agent_specs:
            print(f"Generated: {spec.name}")
"""
from __future__ import annotations

import json
import logging
from dataclasses import dataclass, field
from typing import Any

from api.agentspec_models import (
    AcceptanceSpec,
    AgentSpec,
    TASK_TYPES,
    generate_uuid,
    create_tool_policy,
)
from sqlalchemy.orm import Session
from api.spec_builder import (
    SpecBuilder,
    BuildResult,
    get_spec_builder,
)
from api.spec_validator import (
    validate_spec,
    SpecValidationResult,
)
from api.display_derivation import derive_display_name, derive_icon
from api.octo_schemas import (
    # Exceptions
    OctoSchemaValidationError,
    SchemaValidationError,
    SchemaValidationResult,
    # Validation functions
    validate_agent_spec_schema,
    validate_test_contract_schema,
    validate_octo_outputs,
    # Constants
    AGENT_SPEC_SCHEMA,
    TEST_CONTRACT_SCHEMA,
    VALID_TASK_TYPES as SCHEMA_VALID_TASK_TYPES,
    VALID_TEST_TYPES as SCHEMA_VALID_TEST_TYPES,
)
from api.tool_policy import TOOL_SETS, derive_tool_policy
from api.constraints import (
    ConstraintValidator,
    ConstraintValidationResult,
    ConstraintViolation,
    ToolAvailabilityConstraint,
    ModelLimitConstraint,
    SandboxConstraint,
    ForbiddenPatternConstraint,
    create_constraints_from_payload,
    create_default_constraints,
)

_logger = logging.getLogger(__name__)


# =============================================================================
# Source Type Constants (Feature #189)
# =============================================================================

# Source types for AgentSpec persistence
# These indicate how the spec was created
SOURCE_TYPE_OCTO_GENERATED = "octo_generated"  # Generated by Octo service
SOURCE_TYPE_MANUAL = "manual"                   # Manually created
SOURCE_TYPE_DSPy = "dspy"                       # Generated via DSPy pipeline
SOURCE_TYPE_TEMPLATE = "template"               # Generated from a template
SOURCE_TYPE_IMPORTED = "imported"               # Imported from external source

VALID_SOURCE_TYPES = frozenset([
    SOURCE_TYPE_OCTO_GENERATED,
    SOURCE_TYPE_MANUAL,
    SOURCE_TYPE_DSPy,
    SOURCE_TYPE_TEMPLATE,
    SOURCE_TYPE_IMPORTED,
])


# =============================================================================
# Model Selection Constants (Feature #187)
# =============================================================================

# Valid Claude models for agent execution
VALID_MODELS = frozenset(["sonnet", "opus", "haiku"])

# Default model when no specific selection criteria matches
DEFAULT_MODEL = "sonnet"

# Capabilities that should use haiku (simple/fast tasks)
HAIKU_CAPABILITIES = frozenset({
    "documentation",
    "doc_generation",
    "readme",
    "wiki",
    "changelog",
    "lint",
    "format",
    "simple_audit",
    "smoke_testing",
    "health_check",
    "ping",
    "status",
    "logging",
    "metrics_collection",
    "notification",
    "alerting",
})

# Capabilities that should use opus (complex reasoning tasks)
OPUS_CAPABILITIES = frozenset({
    "architecture_design",
    "system_design",
    "complex_refactoring",
    "security_audit",
    "vulnerability_analysis",
    "performance_optimization",
    "algorithm_design",
    "data_modeling",
    "schema_design",
    "complex_debugging",
    "root_cause_analysis",
    "code_migration",
    "framework_migration",
    "multi_service_integration",
    "distributed_systems",
    "concurrency_design",
    "complex_testing",
    "test_strategy",
    "ml_pipeline",
    "data_pipeline",
})

# Task types that default to specific models
TASK_TYPE_MODEL_DEFAULTS: dict[str, str] = {
    "coding": "sonnet",
    "testing": "sonnet",
    "refactoring": "sonnet",
    "documentation": "haiku",
    "audit": "opus",
    "custom": "sonnet",
}

# Keywords in capability names that indicate complexity
COMPLEXITY_INDICATORS = {
    "complex": "opus",
    "simple": "haiku",
    "advanced": "opus",
    "basic": "haiku",
    "deep": "opus",
    "quick": "haiku",
    "comprehensive": "opus",
    "minimal": "haiku",
    "thorough": "opus",
    "fast": "haiku",
    "multi": "opus",
    "distributed": "opus",
    "concurrent": "opus",
}


# =============================================================================
# Request/Response Schemas
# =============================================================================

# =============================================================================
# Validation Result with Remediation Hints (Feature #190)
# =============================================================================

@dataclass
class PayloadValidationError:
    """
    A single validation error with remediation hint.

    Feature #190: When project context is incomplete or malformed, Octo returns
    helpful errors rather than crashing.
    """
    field: str
    message: str
    severity: str  # "error" (fatal) or "warning" (can proceed with defaults)
    remediation_hint: str
    current_value: Any = None
    default_value: Any = None

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "field": self.field,
            "message": self.message,
            "severity": self.severity,
            "remediation_hint": self.remediation_hint,
            "current_value": repr(self.current_value) if self.current_value is not None else None,
            "default_value": repr(self.default_value) if self.default_value is not None else None,
        }


@dataclass
class PayloadValidationResult:
    """
    Result of validating an OctoRequestPayload.

    Feature #190: Validation results include clear error messages and remediation hints.
    """
    is_valid: bool
    errors: list[PayloadValidationError] = field(default_factory=list)
    warnings: list[PayloadValidationError] = field(default_factory=list)
    defaults_applied: dict[str, Any] = field(default_factory=dict)

    @property
    def error_messages(self) -> list[str]:
        """Get list of error message strings."""
        return [f"{e.field}: {e.message}" for e in self.errors]

    @property
    def warning_messages(self) -> list[str]:
        """Get list of warning message strings."""
        return [f"{w.field}: {w.message}" for w in self.warnings]

    @property
    def remediation_hints(self) -> list[str]:
        """Get list of all remediation hints."""
        all_hints = []
        for e in self.errors:
            if e.remediation_hint:
                all_hints.append(f"[ERROR] {e.field}: {e.remediation_hint}")
        for w in self.warnings:
            if w.remediation_hint:
                all_hints.append(f"[WARNING] {w.field}: {w.remediation_hint}")
        return all_hints

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "is_valid": self.is_valid,
            "errors": [e.to_dict() for e in self.errors],
            "warnings": [w.to_dict() for w in self.warnings],
            "defaults_applied": self.defaults_applied,
            "error_messages": self.error_messages,
            "warning_messages": self.warning_messages,
            "remediation_hints": self.remediation_hints,
        }


# Default values for project_context fields when missing/malformed
_PROJECT_CONTEXT_DEFAULTS = {
    "name": "UnknownProject",
    "tech_stack": [],
    "directory_structure": [],
    "app_spec_summary": "",
    "settings": {},
    "environment": "development",
}


@dataclass
class OctoRequestPayload:
    """
    Structured request payload for Octo agent generation.

    Contains all context Octo needs to generate appropriate AgentSpecs:
    - project_context: Discovery artifacts, tech stack, app spec summary
    - required_capabilities: List of capabilities needed (e.g., "e2e_testing", "api_testing")
    - existing_agents: Names of agents already available (to avoid duplication)
    - constraints: Limits like max_agents, model restrictions, tool restrictions

    Feature #175: Maestro produces structured Octo request payload
    Feature #190: Graceful handling of malformed project context
    """
    project_context: dict[str, Any]
    required_capabilities: list[str]
    existing_agents: list[str] = field(default_factory=list)
    constraints: dict[str, Any] = field(default_factory=dict)

    # Optional metadata for traceability
    source_feature_ids: list[int] = field(default_factory=list)
    request_id: str = field(default_factory=generate_uuid)

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "project_context": self.project_context,
            "required_capabilities": self.required_capabilities,
            "existing_agents": self.existing_agents,
            "constraints": self.constraints,
            "source_feature_ids": self.source_feature_ids,
            "request_id": self.request_id,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "OctoRequestPayload":
        """Create from dictionary."""
        return cls(
            project_context=data.get("project_context", {}),
            required_capabilities=data.get("required_capabilities", []),
            existing_agents=data.get("existing_agents", []),
            constraints=data.get("constraints", {}),
            source_feature_ids=data.get("source_feature_ids", []),
            request_id=data.get("request_id", generate_uuid()),
        )

    def validate(self) -> list[str]:
        """
        Validate the payload structure (basic validation for backward compatibility).

        Returns:
            List of validation error messages (empty if valid)
        """
        # Use detailed validation and extract error messages
        result = self.validate_detailed()
        return result.error_messages

    def validate_detailed(self, apply_defaults: bool = False) -> PayloadValidationResult:
        """
        Validate the payload structure with detailed error information and remediation hints.

        Feature #190: Octo handles malformed project context gracefully.

        This method provides:
        1. Clear error messages for missing required fields
        2. Warnings for partial/malformed context (with defaults applied)
        3. Remediation hints for each validation issue

        Args:
            apply_defaults: If True, apply defaults to malformed fields and report as warnings
                          instead of errors (allows proceeding with partial data)

        Returns:
            PayloadValidationResult with errors, warnings, and remediation hints
        """
        errors: list[PayloadValidationError] = []
        warnings: list[PayloadValidationError] = []
        defaults_applied: dict[str, Any] = {}

        # ============================================
        # Validate project_context (required field)
        # ============================================
        if not isinstance(self.project_context, dict):
            if apply_defaults:
                # Apply default empty dict and warn
                self.project_context = dict(_PROJECT_CONTEXT_DEFAULTS)
                defaults_applied["project_context"] = self.project_context
                warnings.append(PayloadValidationError(
                    field="project_context",
                    message="project_context must be a dictionary, using defaults",
                    severity="warning",
                    remediation_hint="Provide a dict with keys: name, tech_stack, directory_structure, app_spec_summary",
                    current_value=None,
                    default_value=_PROJECT_CONTEXT_DEFAULTS,
                ))
            else:
                errors.append(PayloadValidationError(
                    field="project_context",
                    message="project_context must be a dictionary",
                    severity="error",
                    remediation_hint="Provide a dict with keys: name, tech_stack, directory_structure, app_spec_summary. Example: {'name': 'MyApp', 'tech_stack': ['python', 'react']}",
                    current_value=self.project_context,
                ))
        else:
            # Validate/fix project_context internal structure
            context_issues = self._validate_project_context(apply_defaults)
            for issue in context_issues:
                if issue.severity == "error":
                    errors.append(issue)
                else:
                    warnings.append(issue)
                    if issue.default_value is not None:
                        defaults_applied[f"project_context.{issue.field}"] = issue.default_value

        # ============================================
        # Validate required_capabilities (required field - cannot apply defaults)
        # ============================================
        if not isinstance(self.required_capabilities, list):
            errors.append(PayloadValidationError(
                field="required_capabilities",
                message="required_capabilities must be a list",
                severity="error",
                remediation_hint="Provide a list of capability strings. Example: ['e2e_testing', 'api_testing', 'documentation']",
                current_value=self.required_capabilities,
            ))
        elif len(self.required_capabilities) == 0:
            errors.append(PayloadValidationError(
                field="required_capabilities",
                message="required_capabilities cannot be empty",
                severity="error",
                remediation_hint="Specify at least one capability. Common capabilities: 'e2e_testing', 'api_testing', 'unit_testing', 'documentation', 'security_audit', 'code_review'",
            ))
        else:
            invalid_caps = []
            for i, cap in enumerate(self.required_capabilities):
                if not isinstance(cap, str):
                    invalid_caps.append(f"[{i}] is {type(cap).__name__}, expected string")
                elif not cap.strip():
                    invalid_caps.append(f"[{i}] is empty string")

            if invalid_caps:
                errors.append(PayloadValidationError(
                    field="required_capabilities",
                    message=f"Invalid capabilities: {'; '.join(invalid_caps)}",
                    severity="error",
                    remediation_hint="Each capability must be a non-empty string. Example: ['e2e_testing', 'api_testing']",
                    current_value=self.required_capabilities,
                ))

        # ============================================
        # Validate existing_agents (optional, can apply defaults)
        # ============================================
        if not isinstance(self.existing_agents, list):
            if apply_defaults:
                self.existing_agents = []
                defaults_applied["existing_agents"] = []
                warnings.append(PayloadValidationError(
                    field="existing_agents",
                    message="existing_agents must be a list, using empty list",
                    severity="warning",
                    remediation_hint="Provide a list of agent name strings. Example: ['coder', 'test-runner']",
                    current_value=None,
                    default_value=[],
                ))
            else:
                errors.append(PayloadValidationError(
                    field="existing_agents",
                    message="existing_agents must be a list",
                    severity="error",
                    remediation_hint="Provide a list of agent name strings, or empty list []. Example: ['coder', 'test-runner']",
                    current_value=self.existing_agents,
                ))
        else:
            # Validate individual agents and filter invalid ones in lenient mode
            invalid_agents = []
            valid_agents = []
            for i, agent in enumerate(self.existing_agents):
                if not isinstance(agent, str):
                    invalid_agents.append(f"[{i}] is {type(agent).__name__}, expected string")
                elif not agent.strip():
                    invalid_agents.append(f"[{i}] is empty string")
                else:
                    valid_agents.append(agent)

            if invalid_agents:
                if apply_defaults:
                    self.existing_agents = valid_agents
                    defaults_applied["existing_agents"] = valid_agents
                    warnings.append(PayloadValidationError(
                        field="existing_agents",
                        message=f"Removed invalid entries: {'; '.join(invalid_agents)}",
                        severity="warning",
                        remediation_hint="Each agent name must be a non-empty string. Invalid entries were removed.",
                        default_value=valid_agents,
                    ))
                else:
                    errors.append(PayloadValidationError(
                        field="existing_agents",
                        message=f"Invalid agent entries: {'; '.join(invalid_agents)}",
                        severity="error",
                        remediation_hint="Each agent name must be a non-empty string. Example: ['coder', 'test-runner']",
                        current_value=self.existing_agents,
                    ))

        # ============================================
        # Validate constraints (optional, can apply defaults)
        # ============================================
        if not isinstance(self.constraints, dict):
            if apply_defaults:
                self.constraints = {}
                defaults_applied["constraints"] = {}
                warnings.append(PayloadValidationError(
                    field="constraints",
                    message="constraints must be a dictionary, using empty dict",
                    severity="warning",
                    remediation_hint="Provide a dict with constraint keys. Example: {'max_agents': 5, 'model': 'sonnet'}",
                    current_value=None,
                    default_value={},
                ))
            else:
                errors.append(PayloadValidationError(
                    field="constraints",
                    message="constraints must be a dictionary",
                    severity="error",
                    remediation_hint="Provide a dict with constraint keys, or empty dict {}. Example: {'max_agents': 5, 'model': 'sonnet', 'max_turns_limit': 100}",
                    current_value=self.constraints,
                ))
        else:
            # Validate constraint values
            constraint_issues = self._validate_constraints(apply_defaults)
            for issue in constraint_issues:
                if issue.severity == "error":
                    errors.append(issue)
                else:
                    warnings.append(issue)
                    if issue.default_value is not None:
                        defaults_applied[f"constraints.{issue.field}"] = issue.default_value

        # Determine overall validity
        is_valid = len(errors) == 0

        return PayloadValidationResult(
            is_valid=is_valid,
            errors=errors,
            warnings=warnings,
            defaults_applied=defaults_applied,
        )

    def _validate_project_context(self, apply_defaults: bool) -> list[PayloadValidationError]:
        """
        Validate individual fields within project_context.

        Feature #190: Partial context triggers warnings but proceeds with defaults.
        """
        issues: list[PayloadValidationError] = []

        # Check 'name' field
        name = self.project_context.get("name")
        if name is None:
            if apply_defaults:
                self.project_context["name"] = _PROJECT_CONTEXT_DEFAULTS["name"]
                issues.append(PayloadValidationError(
                    field="name",
                    message="project_context.name is missing, using default",
                    severity="warning",
                    remediation_hint="Provide a project name string for better agent generation. Example: 'name': 'MyWebApp'",
                    default_value=_PROJECT_CONTEXT_DEFAULTS["name"],
                ))
        elif not isinstance(name, str):
            if apply_defaults:
                self.project_context["name"] = str(name) if name else _PROJECT_CONTEXT_DEFAULTS["name"]
                issues.append(PayloadValidationError(
                    field="name",
                    message=f"project_context.name should be a string, converted from {type(name).__name__}",
                    severity="warning",
                    remediation_hint="Provide a string value for the project name.",
                    current_value=name,
                    default_value=self.project_context["name"],
                ))
            else:
                issues.append(PayloadValidationError(
                    field="name",
                    message=f"project_context.name must be a string, got {type(name).__name__}",
                    severity="error",
                    remediation_hint="Provide a string value for the project name. Example: 'name': 'MyWebApp'",
                    current_value=name,
                ))

        # Check 'tech_stack' field
        tech_stack = self.project_context.get("tech_stack")
        if tech_stack is None:
            if apply_defaults:
                self.project_context["tech_stack"] = _PROJECT_CONTEXT_DEFAULTS["tech_stack"]
                issues.append(PayloadValidationError(
                    field="tech_stack",
                    message="project_context.tech_stack is missing, using empty list",
                    severity="warning",
                    remediation_hint="Provide a list of technology strings for better agent generation. Example: 'tech_stack': ['python', 'react', 'fastapi']",
                    default_value=_PROJECT_CONTEXT_DEFAULTS["tech_stack"],
                ))
        elif not isinstance(tech_stack, list):
            if apply_defaults:
                # Try to convert if possible (e.g., comma-separated string)
                if isinstance(tech_stack, str):
                    self.project_context["tech_stack"] = [t.strip() for t in tech_stack.split(",") if t.strip()]
                else:
                    self.project_context["tech_stack"] = _PROJECT_CONTEXT_DEFAULTS["tech_stack"]
                issues.append(PayloadValidationError(
                    field="tech_stack",
                    message=f"project_context.tech_stack should be a list, converted from {type(tech_stack).__name__}",
                    severity="warning",
                    remediation_hint="Provide a list of technology strings. Example: 'tech_stack': ['python', 'react']",
                    current_value=tech_stack,
                    default_value=self.project_context["tech_stack"],
                ))
            else:
                issues.append(PayloadValidationError(
                    field="tech_stack",
                    message=f"project_context.tech_stack must be a list, got {type(tech_stack).__name__}",
                    severity="error",
                    remediation_hint="Provide a list of technology strings. Example: 'tech_stack': ['python', 'react', 'fastapi']",
                    current_value=tech_stack,
                ))

        # Check 'settings' field (optional but should be dict if present)
        settings = self.project_context.get("settings")
        if settings is not None and not isinstance(settings, dict):
            if apply_defaults:
                self.project_context["settings"] = _PROJECT_CONTEXT_DEFAULTS["settings"]
                issues.append(PayloadValidationError(
                    field="settings",
                    message="project_context.settings should be a dict, using empty dict",
                    severity="warning",
                    remediation_hint="Provide a dict for settings if needed. Example: 'settings': {'model': 'sonnet'}",
                    current_value=settings,
                    default_value=_PROJECT_CONTEXT_DEFAULTS["settings"],
                ))
            else:
                issues.append(PayloadValidationError(
                    field="settings",
                    message=f"project_context.settings must be a dict, got {type(settings).__name__}",
                    severity="error",
                    remediation_hint="Provide a dict for settings, or remove the field. Example: 'settings': {'model': 'sonnet'}",
                    current_value=settings,
                ))

        return issues

    def _validate_constraints(self, apply_defaults: bool) -> list[PayloadValidationError]:
        """
        Validate individual constraint fields.

        Feature #190: Validate constraint values and provide remediation hints.
        """
        issues: list[PayloadValidationError] = []

        # Validate 'max_agents' if present
        max_agents = self.constraints.get("max_agents")
        if max_agents is not None:
            if not isinstance(max_agents, int) or max_agents < 1:
                if apply_defaults:
                    self.constraints["max_agents"] = 10
                    issues.append(PayloadValidationError(
                        field="max_agents",
                        message="constraints.max_agents must be positive integer, using default 10",
                        severity="warning",
                        remediation_hint="Provide a positive integer. Example: 'max_agents': 5",
                        current_value=max_agents,
                        default_value=10,
                    ))
                else:
                    issues.append(PayloadValidationError(
                        field="max_agents",
                        message=f"constraints.max_agents must be a positive integer, got {repr(max_agents)}",
                        severity="error",
                        remediation_hint="Provide a positive integer. Example: 'max_agents': 5",
                        current_value=max_agents,
                    ))

        # Validate 'model' if present
        model = self.constraints.get("model")
        if model is not None:
            if not isinstance(model, str) or model.lower() not in VALID_MODELS:
                if apply_defaults:
                    self.constraints["model"] = DEFAULT_MODEL
                    issues.append(PayloadValidationError(
                        field="model",
                        message=f"constraints.model must be one of {sorted(VALID_MODELS)}, using '{DEFAULT_MODEL}'",
                        severity="warning",
                        remediation_hint=f"Use one of: {', '.join(sorted(VALID_MODELS))}. Example: 'model': 'sonnet'",
                        current_value=model,
                        default_value=DEFAULT_MODEL,
                    ))
                else:
                    issues.append(PayloadValidationError(
                        field="model",
                        message=f"constraints.model must be one of {sorted(VALID_MODELS)}, got {repr(model)}",
                        severity="error",
                        remediation_hint=f"Use one of: {', '.join(sorted(VALID_MODELS))}. Example: 'model': 'sonnet'",
                        current_value=model,
                    ))

        # Validate 'max_turns_limit' if present
        max_turns = self.constraints.get("max_turns_limit")
        if max_turns is not None:
            if not isinstance(max_turns, int) or max_turns < 1:
                if apply_defaults:
                    self.constraints["max_turns_limit"] = 100
                    issues.append(PayloadValidationError(
                        field="max_turns_limit",
                        message="constraints.max_turns_limit must be positive integer, using default 100",
                        severity="warning",
                        remediation_hint="Provide a positive integer. Example: 'max_turns_limit': 100",
                        current_value=max_turns,
                        default_value=100,
                    ))
                else:
                    issues.append(PayloadValidationError(
                        field="max_turns_limit",
                        message=f"constraints.max_turns_limit must be a positive integer, got {repr(max_turns)}",
                        severity="error",
                        remediation_hint="Provide a positive integer. Example: 'max_turns_limit': 100",
                        current_value=max_turns,
                    ))

        return issues


@dataclass
class OctoResponse:
    """
    Response from Octo containing generated AgentSpecs and TestContracts.

    Feature #184: Octo generates TestContract alongside AgentSpec when applicable
    Feature #185: Octo DSPy module with constraint satisfaction
    Feature #188: Octo outputs are strictly typed and schema-validated
    """
    success: bool
    agent_specs: list[AgentSpec] = field(default_factory=list)
    test_contracts: list["TestContract"] = field(default_factory=list)  # Feature #184
    constraint_violations: list[ConstraintViolation] = field(default_factory=list)  # Feature #185
    error: str | None = None
    error_type: str | None = None
    validation_errors: list[str] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)
    request_id: str | None = None

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "success": self.success,
            "agent_specs": [spec.to_dict() for spec in self.agent_specs],
            "test_contracts": [tc.to_dict() for tc in self.test_contracts],
            "constraint_violations": [cv.to_dict() for cv in self.constraint_violations],
            "error": self.error,
            "error_type": self.error_type,
            "validation_errors": self.validation_errors,
            "warnings": self.warnings,
            "request_id": self.request_id,
        }


@dataclass
class SpecPersistenceResult:
    """
    Result of persisting an AgentSpec to the database.

    Feature #189: Octo persists AgentSpecs to database

    This result is returned when calling persist_spec() or persist_specs().
    It tracks whether the spec was successfully saved to the database and
    includes any errors that occurred during persistence.

    Attributes:
        spec_id: The ID of the persisted AgentSpec
        spec_name: Name of the AgentSpec
        success: Whether persistence succeeded
        error: Error message if persistence failed
        source_type: The source_type stored with the spec
        project_name: The project this spec is associated with
        octo_request_id: The Octo request ID that triggered generation
    """
    spec_id: str
    spec_name: str
    success: bool
    error: str | None = None
    source_type: str = SOURCE_TYPE_OCTO_GENERATED
    project_name: str | None = None
    octo_request_id: str | None = None

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "spec_id": self.spec_id,
            "spec_name": self.spec_name,
            "success": self.success,
            "error": self.error,
            "source_type": self.source_type,
            "project_name": self.project_name,
            "octo_request_id": self.octo_request_id,
        }


# =============================================================================
# TestContract - Structured Test Specification (Feature #184)
# =============================================================================

# Test types supported by TestContract
TEST_TYPES = [
    "unit",           # Unit tests for isolated components
    "integration",    # Integration tests for component interactions
    "e2e",            # End-to-end UI tests
    "api",            # API endpoint tests
    "performance",    # Performance and load tests
    "security",       # Security scanning/audit tests
    "smoke",          # Quick sanity check tests
    "regression",     # Regression tests for existing functionality
]


@dataclass
class TestContractAssertion:
    """
    A single assertion within a TestContract.

    Assertions describe what conditions must hold true for a test to pass.
    They are structured data, not executable code.

    Attributes:
        description: Human-readable description of what is being asserted
        target: What is being tested (e.g., "response.status_code", "page.title")
        expected: Expected value or condition
        operator: Comparison operator (eq, ne, gt, lt, ge, le, contains, matches)
    """
    description: str
    target: str
    expected: Any
    operator: str = "eq"  # eq, ne, gt, lt, ge, le, contains, matches, exists

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "description": self.description,
            "target": self.target,
            "expected": self.expected,
            "operator": self.operator,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "TestContractAssertion":
        """Create from dictionary."""
        return cls(
            description=data.get("description", ""),
            target=data.get("target", ""),
            expected=data.get("expected"),
            operator=data.get("operator", "eq"),
        )


# =============================================================================
# TestDependency - Test Dependencies Schema (Feature #209)
# =============================================================================

# Valid dependency types for TestDependency
DEPENDENCY_TYPES = [
    "fixture",     # Test fixture (setup data, database state)
    "mock",        # Mock object or stub
    "service",     # External service dependency
    "database",    # Database dependency (schema, data)
    "file",        # File system dependency
    "environment", # Environment variable or config
    "api",         # API endpoint dependency
    "component",   # Component or module dependency
]


@dataclass
class TestDependency:
    """
    A single dependency required by a TestContract.

    Feature #209: TestContract includes dependencies (fixtures, mocks needed).

    Dependencies describe what external resources, fixtures, or mocks are
    needed to execute the test. They are structured data that helps test
    generators set up the necessary test environment.

    Attributes:
        name: Unique identifier for the dependency (e.g., "user_fixture", "api_mock")
        dependency_type: Type of dependency (fixture, mock, service, database, etc.)
        description: Human-readable description of the dependency purpose
        setup_hints: Optional hints for how to set up the dependency
        required: Whether this dependency is required or optional
    """
    name: str
    dependency_type: str
    description: str = ""
    setup_hints: list[str] = field(default_factory=list)
    required: bool = True

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "name": self.name,
            "dependency_type": self.dependency_type,
            "description": self.description,
            "setup_hints": self.setup_hints,
            "required": self.required,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "TestDependency":
        """Create from dictionary."""
        return cls(
            name=data.get("name", ""),
            dependency_type=data.get("dependency_type", "fixture"),
            description=data.get("description", ""),
            setup_hints=data.get("setup_hints", []),
            required=data.get("required", True),
        )

    def validate(self) -> list[str]:
        """
        Validate the TestDependency structure.

        Returns:
            List of validation error messages (empty if valid)
        """
        errors: list[str] = []

        if not self.name or not self.name.strip():
            errors.append("dependency name is required")

        if not self.dependency_type:
            errors.append("dependency_type is required")
        elif self.dependency_type not in DEPENDENCY_TYPES:
            errors.append(f"dependency_type must be one of: {', '.join(DEPENDENCY_TYPES)}")

        return errors


@dataclass
class TestContract:
    """
    Structured test specification for testable agent responsibilities.

    Feature #184: Octo generates TestContract alongside AgentSpec when applicable.
    Feature #209: TestContract schema defined and documented.

    TestContract specifies WHAT should be tested, not HOW to test it.
    It is structured data (not test code) that can be used by:
    - Test generation tools to create actual test code
    - Acceptance validators to verify agent output
    - Documentation to describe expected behavior

    Schema Fields (Feature #209):
        test_name: Human-readable name for this test contract
        test_type: Type of testing (unit, integration, e2e, api, performance, security, etc.)
        subject: What is being tested (component, function, feature, endpoint)
        assertions: List of assertions that describe expected behaviors
        pass_criteria: Conditions that determine test success
        fail_criteria: Conditions that indicate test failure
        dependencies: List of fixtures, mocks, and other dependencies needed

    Additional Fields:
        agent_name: Name of the agent this contract is linked to (matches AgentSpec.name)
        description: Human-readable description of what is being tested
        priority: Priority level (1=critical, 2=high, 3=medium, 4=low)
        tags: Optional tags for categorization
        contract_id: Unique identifier for the contract
    """
    # Required fields (Feature #209)
    agent_name: str
    test_type: str

    # Feature #209: New required fields
    test_name: str = ""  # Human-readable name for the test
    subject: str = ""    # What is being tested

    # Assertions and criteria
    assertions: list[TestContractAssertion] = field(default_factory=list)
    pass_criteria: list[str] = field(default_factory=list)
    fail_criteria: list[str] = field(default_factory=list)

    # Feature #209: Dependencies (fixtures, mocks needed)
    dependencies: list[TestDependency] = field(default_factory=list)

    # Metadata
    description: str = ""
    priority: int = 3  # 1=critical, 2=high, 3=medium, 4=low
    tags: list[str] = field(default_factory=list)
    contract_id: str = field(default_factory=generate_uuid)

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "contract_id": self.contract_id,
            "test_name": self.test_name,
            "agent_name": self.agent_name,
            "test_type": self.test_type,
            "subject": self.subject,
            "assertions": [a.to_dict() for a in self.assertions],
            "pass_criteria": self.pass_criteria,
            "fail_criteria": self.fail_criteria,
            "dependencies": [d.to_dict() for d in self.dependencies],
            "description": self.description,
            "priority": self.priority,
            "tags": self.tags,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "TestContract":
        """Create from dictionary."""
        assertions = [
            TestContractAssertion.from_dict(a)
            for a in data.get("assertions", [])
        ]
        dependencies = [
            TestDependency.from_dict(d)
            for d in data.get("dependencies", [])
        ]
        return cls(
            agent_name=data.get("agent_name", ""),
            test_type=data.get("test_type", "unit"),
            test_name=data.get("test_name", ""),
            subject=data.get("subject", ""),
            assertions=assertions,
            pass_criteria=data.get("pass_criteria", []),
            fail_criteria=data.get("fail_criteria", []),
            dependencies=dependencies,
            description=data.get("description", ""),
            priority=data.get("priority", 3),
            tags=data.get("tags", []),
            contract_id=data.get("contract_id", generate_uuid()),
        )

    def validate(self) -> list[str]:
        """
        Validate the TestContract structure.

        Feature #209: Schema documented and validated.

        Returns:
            List of validation error messages (empty if valid)
        """
        errors: list[str] = []

        # Required field validations
        if not self.agent_name or not self.agent_name.strip():
            errors.append("agent_name is required")

        if not self.test_type:
            errors.append("test_type is required")
        elif self.test_type not in TEST_TYPES:
            errors.append(f"test_type must be one of: {', '.join(TEST_TYPES)}")

        # Assertions or pass_criteria required
        if not self.assertions and not self.pass_criteria:
            errors.append("TestContract must have either assertions or pass_criteria")

        # Priority validation
        if self.priority not in (1, 2, 3, 4):
            errors.append("priority must be 1 (critical), 2 (high), 3 (medium), or 4 (low)")

        # Validate dependencies (Feature #209)
        for i, dep in enumerate(self.dependencies):
            dep_errors = dep.validate()
            for err in dep_errors:
                errors.append(f"dependencies[{i}]: {err}")

        return errors


# =============================================================================
# Testability Evaluation (Feature #184)
# =============================================================================

# Capabilities that are inherently testable
TESTABLE_CAPABILITIES = frozenset({
    # Testing-related capabilities
    "e2e_testing",
    "api_testing",
    "ui_testing",
    "unit_testing",
    "integration_testing",
    "performance_testing",
    "security_testing",
    "load_testing",
    "smoke_testing",
    "regression_testing",
    # Coding capabilities with testable output
    "coding",
    "refactoring",
    "bug_fixing",
    "feature_implementation",
    # API-related capabilities
    "api_implementation",
    "api_design",
    "rest_api",
    "graphql",
    # Frontend capabilities
    "frontend",
    "ui_development",
    "component_development",
    # Backend capabilities
    "backend",
    "database",
    "data_processing",
})

# Task types that are testable
TESTABLE_TASK_TYPES = frozenset({
    "coding",
    "testing",
    "refactoring",
})

# Keywords in objectives that indicate testability
TESTABLE_OBJECTIVE_KEYWORDS = [
    "implement",
    "create",
    "build",
    "develop",
    "test",
    "verify",
    "validate",
    "check",
    "ensure",
    "api",
    "endpoint",
    "function",
    "component",
    "feature",
    "fix",
    "bug",
    "refactor",
]


def is_capability_testable(capability: str) -> bool:
    """
    Check if a capability is inherently testable.

    Args:
        capability: The capability name to check

    Returns:
        True if the capability has testable responsibilities
    """
    capability_lower = capability.lower().replace("-", "_").replace(" ", "_")
    return capability_lower in TESTABLE_CAPABILITIES


def is_task_type_testable(task_type: str) -> bool:
    """
    Check if a task type typically produces testable output.

    Args:
        task_type: The task type to check

    Returns:
        True if the task type is testable
    """
    return task_type in TESTABLE_TASK_TYPES


def is_objective_testable(objective: str) -> bool:
    """
    Analyze an objective string to determine if it describes testable work.

    Args:
        objective: The agent's objective description

    Returns:
        True if the objective describes testable responsibilities
    """
    if not objective:
        return False

    objective_lower = objective.lower()

    # Check for testability keywords
    return any(keyword in objective_lower for keyword in TESTABLE_OBJECTIVE_KEYWORDS)


def evaluate_agent_testability(
    capability: str,
    task_type: str,
    objective: str,
) -> tuple[bool, str]:
    """
    Evaluate whether an agent has testable responsibilities.

    Feature #184: Octo evaluates if agent responsibilities are testable.

    Combines multiple signals to determine testability:
    1. Capability name (e.g., "e2e_testing" is testable)
    2. Task type (e.g., "coding" produces testable output)
    3. Objective keywords (e.g., "implement API endpoint" is testable)

    Args:
        capability: The agent's capability
        task_type: The agent's task type
        objective: The agent's objective description

    Returns:
        Tuple of (is_testable, reason_string)
    """
    reasons = []

    # Check capability
    if is_capability_testable(capability):
        reasons.append(f"capability '{capability}' is testable")

    # Check task type
    if is_task_type_testable(task_type):
        reasons.append(f"task_type '{task_type}' produces testable output")

    # Check objective
    if is_objective_testable(objective):
        reasons.append("objective describes testable work")

    if reasons:
        return True, "; ".join(reasons)
    else:
        return False, "no testable responsibilities identified"


def generate_test_contract(
    agent_spec: AgentSpec,
    capability: str,
    project_context: dict[str, Any] | None = None,
) -> TestContract | None:
    """
    Generate a TestContract for an AgentSpec if it has testable responsibilities.

    Feature #184: For testable agents, Octo generates TestContract structure.

    Args:
        agent_spec: The AgentSpec to generate a contract for
        capability: The capability this agent was created for
        project_context: Optional project context for richer contracts

    Returns:
        TestContract if the agent is testable, None otherwise
    """
    # Step 1: Evaluate testability
    is_testable, reason = evaluate_agent_testability(
        capability=capability,
        task_type=agent_spec.task_type,
        objective=agent_spec.objective,
    )

    if not is_testable:
        _logger.debug(
            "Agent %s is not testable: %s",
            agent_spec.name,
            reason,
        )
        return None

    _logger.info(
        "Generating TestContract for agent %s: %s",
        agent_spec.name,
        reason,
    )

    # Step 2: Determine test type based on capability/task
    test_type = _infer_test_type(capability, agent_spec.task_type)

    # Step 3: Generate assertions based on capability
    assertions = _generate_assertions(capability, agent_spec, project_context)

    # Step 4: Generate pass/fail criteria
    pass_criteria, fail_criteria = _generate_criteria(capability, agent_spec)

    # Step 5: Generate test name and subject (Feature #209)
    test_name = _generate_test_name(capability, agent_spec)
    subject = _generate_subject(capability, agent_spec)

    # Step 6: Generate dependencies (Feature #209)
    dependencies = _generate_dependencies(capability, agent_spec, project_context)

    # Step 7: Build the TestContract
    contract = TestContract(
        agent_name=agent_spec.name,
        test_type=test_type,
        test_name=test_name,
        subject=subject,
        assertions=assertions,
        pass_criteria=pass_criteria,
        fail_criteria=fail_criteria,
        dependencies=dependencies,
        description=f"Test contract for {agent_spec.display_name}: verifies {capability} responsibilities",
        priority=_infer_priority(capability, agent_spec.task_type),
        tags=_generate_tags(capability, agent_spec),
    )

    return contract


def _infer_test_type(capability: str, task_type: str) -> str:
    """Infer the appropriate test type from capability and task type."""
    capability_lower = capability.lower()

    # Explicit testing capabilities
    if "e2e" in capability_lower or "ui" in capability_lower:
        return "e2e"
    if "api" in capability_lower:
        return "api"
    if "unit" in capability_lower:
        return "unit"
    if "integration" in capability_lower:
        return "integration"
    if "performance" in capability_lower or "load" in capability_lower:
        return "performance"
    if "security" in capability_lower:
        return "security"
    if "smoke" in capability_lower:
        return "smoke"
    if "regression" in capability_lower:
        return "regression"

    # Infer from task type
    if task_type == "testing":
        return "integration"
    if task_type == "coding":
        return "unit"
    if task_type == "refactoring":
        return "regression"

    return "unit"  # Default


def _generate_assertions(
    capability: str,
    agent_spec: AgentSpec,
    project_context: dict[str, Any] | None,
) -> list[TestContractAssertion]:
    """Generate assertions based on capability and context."""
    assertions = []
    capability_lower = capability.lower()

    # API-related assertions
    if "api" in capability_lower:
        assertions.extend([
            TestContractAssertion(
                description="API endpoints return successful status codes",
                target="response.status_code",
                expected=200,
                operator="eq",
            ),
            TestContractAssertion(
                description="API responses are valid JSON",
                target="response.content_type",
                expected="application/json",
                operator="contains",
            ),
        ])

    # E2E/UI assertions
    if "e2e" in capability_lower or "ui" in capability_lower:
        assertions.extend([
            TestContractAssertion(
                description="Page loads successfully",
                target="page.status",
                expected="loaded",
                operator="eq",
            ),
            TestContractAssertion(
                description="No JavaScript errors in console",
                target="console.errors.count",
                expected=0,
                operator="eq",
            ),
        ])

    # Coding/implementation assertions
    if capability_lower in ("coding", "refactoring", "feature_implementation"):
        assertions.extend([
            TestContractAssertion(
                description="Code compiles/builds without errors",
                target="build.status",
                expected="success",
                operator="eq",
            ),
            TestContractAssertion(
                description="Linting passes",
                target="lint.errors.count",
                expected=0,
                operator="eq",
            ),
        ])

    # Security assertions
    if "security" in capability_lower:
        assertions.extend([
            TestContractAssertion(
                description="No critical vulnerabilities found",
                target="vulnerabilities.critical.count",
                expected=0,
                operator="eq",
            ),
            TestContractAssertion(
                description="No high severity vulnerabilities found",
                target="vulnerabilities.high.count",
                expected=0,
                operator="eq",
            ),
        ])

    # Default assertion if none generated
    if not assertions:
        assertions.append(
            TestContractAssertion(
                description=f"Agent {agent_spec.name} completes successfully",
                target="agent.status",
                expected="completed",
                operator="eq",
            )
        )

    return assertions


def _generate_criteria(
    capability: str,
    agent_spec: AgentSpec,
) -> tuple[list[str], list[str]]:
    """Generate pass and fail criteria based on capability."""
    capability_lower = capability.lower()

    pass_criteria = []
    fail_criteria = []

    # Common pass criteria
    pass_criteria.append("Agent completes without errors")
    pass_criteria.append("All required outputs are generated")

    # Capability-specific pass criteria
    if "test" in capability_lower:
        pass_criteria.append("All tests pass")
        pass_criteria.append("Test coverage meets minimum threshold")
        fail_criteria.append("Any test fails")

    if "api" in capability_lower:
        pass_criteria.append("All API endpoints respond correctly")
        pass_criteria.append("Response times are within acceptable limits")
        fail_criteria.append("Any endpoint returns 5xx error")

    if "e2e" in capability_lower or "ui" in capability_lower:
        pass_criteria.append("All user flows complete successfully")
        pass_criteria.append("No visual regressions detected")
        fail_criteria.append("Any critical user flow fails")

    if "security" in capability_lower:
        pass_criteria.append("No critical vulnerabilities found")
        pass_criteria.append("Security scan completes successfully")
        fail_criteria.append("Critical vulnerability detected")

    if capability_lower in ("coding", "refactoring"):
        pass_criteria.append("Code compiles successfully")
        pass_criteria.append("Linting passes")
        fail_criteria.append("Build fails")
        fail_criteria.append("Linting errors detected")

    # Common fail criteria
    fail_criteria.append("Agent times out")
    fail_criteria.append("Agent crashes or raises unhandled exception")

    return pass_criteria, fail_criteria


def _infer_priority(capability: str, task_type: str) -> int:
    """Infer priority level (1=critical to 4=low)."""
    capability_lower = capability.lower()

    # Critical priority
    if "security" in capability_lower:
        return 1
    if "auth" in capability_lower:
        return 1

    # High priority
    if "api" in capability_lower:
        return 2
    if "e2e" in capability_lower:
        return 2
    if task_type == "testing":
        return 2

    # Medium priority
    if task_type == "coding":
        return 3
    if "unit" in capability_lower:
        return 3

    # Low priority
    return 4


def _generate_test_name(capability: str, agent_spec: AgentSpec) -> str:
    """
    Generate a human-readable test name for the TestContract.

    Feature #209: TestContract includes test_name.

    Args:
        capability: The capability this test is for
        agent_spec: The AgentSpec being tested

    Returns:
        Human-readable test name
    """
    capability_lower = capability.lower().replace("_", " ").replace("-", " ")

    # Use display name if available, otherwise format agent name
    agent_display = agent_spec.display_name or agent_spec.name.replace("-", " ").title()

    return f"{agent_display} - {capability_lower.title()} Tests"


def _generate_subject(capability: str, agent_spec: AgentSpec) -> str:
    """
    Generate the test subject (what is being tested).

    Feature #209: TestContract includes subject (what to test).

    Args:
        capability: The capability this test is for
        agent_spec: The AgentSpec being tested

    Returns:
        Description of what is being tested
    """
    capability_lower = capability.lower()

    # API-related subjects
    if "api" in capability_lower:
        return "API endpoint functionality and response handling"

    # E2E/UI subjects
    if "e2e" in capability_lower or "ui" in capability_lower:
        return "User interface interactions and page workflows"

    # Security subjects
    if "security" in capability_lower:
        return "Security controls and vulnerability protection"

    # Performance subjects
    if "performance" in capability_lower or "load" in capability_lower:
        return "System performance under load"

    # Testing capability subjects
    if "unit" in capability_lower:
        return "Individual component behavior in isolation"
    if "integration" in capability_lower:
        return "Component interactions and integration points"

    # Coding/refactoring subjects
    if capability_lower in ("coding", "refactoring", "feature_implementation"):
        context = agent_spec.context or {}
        if "feature_id" in context:
            return f"Feature #{context['feature_id']} implementation"
        return "Code implementation correctness and quality"

    # Default based on objective
    if agent_spec.objective:
        # Extract first sentence or 100 chars from objective
        objective = agent_spec.objective.split(".")[0]
        if len(objective) > 100:
            objective = objective[:100] + "..."
        return objective

    return "Agent responsibilities and output quality"


def _generate_dependencies(
    capability: str,
    agent_spec: AgentSpec,
    project_context: dict[str, Any] | None,
) -> list[TestDependency]:
    """
    Generate dependencies (fixtures, mocks) needed for the test.

    Feature #209: TestContract includes dependencies (fixtures, mocks needed).

    Args:
        capability: The capability this test is for
        agent_spec: The AgentSpec being tested
        project_context: Optional project context for richer dependencies

    Returns:
        List of TestDependency objects
    """
    dependencies: list[TestDependency] = []
    capability_lower = capability.lower()

    # API-related dependencies
    if "api" in capability_lower:
        dependencies.append(TestDependency(
            name="api_server",
            dependency_type="service",
            description="Running API server instance",
            setup_hints=["Start development server", "Configure test database connection"],
            required=True,
        ))
        dependencies.append(TestDependency(
            name="test_database",
            dependency_type="database",
            description="Test database with seed data",
            setup_hints=["Run migrations", "Load test fixtures"],
            required=True,
        ))

    # E2E/UI dependencies
    if "e2e" in capability_lower or "ui" in capability_lower:
        dependencies.append(TestDependency(
            name="browser_automation",
            dependency_type="service",
            description="Browser automation framework (Playwright/Selenium)",
            setup_hints=["Install browser binaries", "Configure browser options"],
            required=True,
        ))
        dependencies.append(TestDependency(
            name="frontend_server",
            dependency_type="service",
            description="Running frontend development server",
            setup_hints=["npm run dev", "Wait for compilation"],
            required=True,
        ))

    # Security testing dependencies
    if "security" in capability_lower:
        dependencies.append(TestDependency(
            name="security_scanner",
            dependency_type="service",
            description="Security scanning tool",
            setup_hints=["Configure security scanner", "Set up vulnerability database"],
            required=True,
        ))

    # Performance testing dependencies
    if "performance" in capability_lower or "load" in capability_lower:
        dependencies.append(TestDependency(
            name="load_testing_tool",
            dependency_type="service",
            description="Load testing framework",
            setup_hints=["Configure load parameters", "Set up monitoring"],
            required=True,
        ))

    # Unit testing dependencies
    if "unit" in capability_lower or capability_lower in ("coding", "refactoring"):
        dependencies.append(TestDependency(
            name="test_framework",
            dependency_type="service",
            description="Unit testing framework (pytest/jest)",
            setup_hints=["Install test dependencies", "Configure test runner"],
            required=True,
        ))

    # Add common dependencies based on project context
    if project_context:
        tech_stack = project_context.get("tech_stack", [])

        # Python-specific dependencies
        if "python" in tech_stack or "fastapi" in tech_stack or "django" in tech_stack:
            if not any(d.name == "test_framework" for d in dependencies):
                dependencies.append(TestDependency(
                    name="pytest_fixtures",
                    dependency_type="fixture",
                    description="Common pytest fixtures",
                    setup_hints=["Create conftest.py", "Define fixtures"],
                    required=False,
                ))

        # JavaScript/TypeScript dependencies
        if any(t in tech_stack for t in ["node", "react", "vue", "typescript", "javascript"]):
            if not any(d.name == "test_framework" for d in dependencies):
                dependencies.append(TestDependency(
                    name="jest_config",
                    dependency_type="fixture",
                    description="Jest test configuration",
                    setup_hints=["Create jest.config.js", "Configure test environment"],
                    required=False,
                ))

    return dependencies


def _generate_tags(capability: str, agent_spec: AgentSpec) -> list[str]:
    """Generate tags for the TestContract."""
    tags = []

    # Add capability as tag
    tags.append(capability.lower().replace(" ", "-"))

    # Add task type as tag
    tags.append(agent_spec.task_type)

    # Add specific tags based on capability
    capability_lower = capability.lower()
    if "api" in capability_lower:
        tags.append("api")
    if "e2e" in capability_lower or "ui" in capability_lower:
        tags.append("ui")
    if "security" in capability_lower:
        tags.append("security")
    if "performance" in capability_lower:
        tags.append("performance")

    return list(set(tags))  # Deduplicate


# =============================================================================
# Model Selection (Feature #187)
# =============================================================================

def select_model_for_capability(
    capability: str,
    task_type: str,
    constraints: dict[str, Any] | None = None,
    project_settings: dict[str, Any] | None = None,
) -> str:
    """
    Select the appropriate Claude model for an agent based on capability and complexity.

    Feature #187: Octo selects appropriate model for each agent

    Model selection follows this priority order:
    1. Project settings override (if specified)
    2. Constraints model_preference (from OctoRequestPayload)
    3. Explicit capability match (HAIKU_CAPABILITIES or OPUS_CAPABILITIES)
    4. Complexity keywords in capability name
    5. Task type defaults
    6. Default model (sonnet)

    Args:
        capability: The capability name for the agent (e.g., "e2e_testing", "security_audit")
        task_type: The task type (coding, testing, audit, etc.)
        constraints: Optional constraints dict from OctoRequestPayload
        project_settings: Optional project-level settings for model override

    Returns:
        Model name: "sonnet", "opus", or "haiku"

    Examples:
        >>> select_model_for_capability("documentation", "documentation")
        'haiku'
        >>> select_model_for_capability("security_audit", "audit")
        'opus'
        >>> select_model_for_capability("coding", "coding")
        'sonnet'
        >>> select_model_for_capability("e2e_testing", "testing", project_settings={"model": "opus"})
        'opus'
    """
    constraints = constraints or {}
    project_settings = project_settings or {}

    # Priority 1: Project settings override
    if "model" in project_settings:
        model = project_settings["model"].lower()
        if model in VALID_MODELS:
            _logger.debug(
                "Model '%s' selected from project_settings for capability '%s'",
                model, capability
            )
            return model

    # Alternative key names for project settings
    for key in ("default_model", "model_preference", "agent_model"):
        if key in project_settings:
            model = project_settings[key].lower()
            if model in VALID_MODELS:
                _logger.debug(
                    "Model '%s' selected from project_settings[%s] for capability '%s'",
                    model, key, capability
                )
                return model

    # Priority 2: Constraints model_preference
    if "model_preference" in constraints:
        model = constraints["model_preference"].lower()
        if model in VALID_MODELS:
            _logger.debug(
                "Model '%s' selected from constraints for capability '%s'",
                model, capability
            )
            return model

    # Priority 3: Explicit capability match
    capability_lower = capability.lower().replace("-", "_").replace(" ", "_")

    if capability_lower in HAIKU_CAPABILITIES:
        _logger.debug(
            "Model 'haiku' selected for simple capability '%s'",
            capability
        )
        return "haiku"

    if capability_lower in OPUS_CAPABILITIES:
        _logger.debug(
            "Model 'opus' selected for complex capability '%s'",
            capability
        )
        return "opus"

    # Priority 4: Complexity keywords in capability name
    for keyword, model in COMPLEXITY_INDICATORS.items():
        if keyword in capability_lower:
            _logger.debug(
                "Model '%s' selected due to keyword '%s' in capability '%s'",
                model, keyword, capability
            )
            return model

    # Priority 5: Task type defaults
    if task_type in TASK_TYPE_MODEL_DEFAULTS:
        model = TASK_TYPE_MODEL_DEFAULTS[task_type]
        _logger.debug(
            "Model '%s' selected from task_type default for '%s' (capability '%s')",
            model, task_type, capability
        )
        return model

    # Priority 6: Default model
    _logger.debug(
        "Default model '%s' selected for capability '%s'",
        DEFAULT_MODEL, capability
    )
    return DEFAULT_MODEL


def validate_model(model: str) -> tuple[bool, str]:
    """
    Validate that a model name is valid.

    Args:
        model: The model name to validate

    Returns:
        Tuple of (is_valid, normalized_model_or_error_message)
    """
    if not model:
        return False, "Model cannot be empty"

    model_lower = model.lower()
    if model_lower in VALID_MODELS:
        return True, model_lower

    return False, f"Invalid model '{model}'. Must be one of: {', '.join(sorted(VALID_MODELS))}"


def get_model_characteristics(model: str) -> dict[str, Any]:
    """
    Get characteristics and recommendations for a model.

    Args:
        model: The model name (sonnet, opus, haiku)

    Returns:
        Dictionary with model characteristics

    Example:
        >>> get_model_characteristics("opus")
        {'name': 'opus', 'complexity': 'high', 'cost': 'high', ...}
    """
    characteristics = {
        "haiku": {
            "name": "haiku",
            "complexity": "low",
            "cost": "low",
            "speed": "fast",
            "use_cases": [
                "Documentation generation",
                "Simple formatting",
                "Quick audits",
                "Status checks",
                "Notifications",
            ],
            "recommended_max_turns": 30,
            "recommended_timeout_seconds": 600,
        },
        "sonnet": {
            "name": "sonnet",
            "complexity": "medium",
            "cost": "medium",
            "speed": "balanced",
            "use_cases": [
                "Standard coding tasks",
                "Testing implementation",
                "Code refactoring",
                "API development",
                "Feature implementation",
            ],
            "recommended_max_turns": 100,
            "recommended_timeout_seconds": 1800,
        },
        "opus": {
            "name": "opus",
            "complexity": "high",
            "cost": "high",
            "speed": "slower",
            "use_cases": [
                "Complex architecture design",
                "Security audits",
                "Performance optimization",
                "Multi-service integration",
                "Root cause analysis",
            ],
            "recommended_max_turns": 150,
            "recommended_timeout_seconds": 3600,
        },
    }

    model_lower = model.lower()
    return characteristics.get(model_lower, characteristics["sonnet"])


# =============================================================================
# Octo Service Class
# =============================================================================

class Octo:
    """
    Octo service for generating AgentSpecs from structured request payloads.

    Octo uses DSPy (via SpecBuilder) to generate AgentSpecs based on:
    - Project context (tech stack, features, environment)
    - Required capabilities (what the agents need to do)
    - Existing agents (to avoid duplication)
    - Constraints (budget limits, model preferences)

    Each generated AgentSpec is validated against the schema before being
    returned to Maestro.

    Feature #176: Maestro delegates to Octo for agent generation
    Feature #183: Octo processes OctoRequestPayload and returns AgentSpecs
    """

    def __init__(
        self,
        api_key: str | None = None,
        *,
        spec_builder: SpecBuilder | None = None,
    ):
        """
        Initialize Octo service.

        Args:
            api_key: Anthropic API key (uses environment if not provided)
            spec_builder: Optional SpecBuilder instance (creates new if not provided)
        """
        self._api_key = api_key

        # Use provided builder or get/create singleton
        if spec_builder is not None:
            self._builder = spec_builder
        else:
            self._builder = get_spec_builder(
                api_key=api_key,
                force_new=api_key is not None,
            )

        _logger.info("Octo service initialized")

    def generate_specs(
        self,
        payload: OctoRequestPayload,
        *,
        lenient: bool = False,
    ) -> OctoResponse:
        """
        Generate AgentSpecs from the request payload.

        This is the main entry point for Octo. It:
        1. Validates the payload structure
        2. Maps required capabilities to task descriptions
        3. Invokes DSPy SpecBuilder for each capability
        4. Validates each generated AgentSpec against schema
        5. Generates TestContracts for testable agents (Feature #184)
        6. Returns all valid specs and contracts in the response

        Feature #190: Octo handles malformed project context gracefully.

        Args:
            payload: OctoRequestPayload containing context and requirements
            lenient: If True, proceed with defaults when project context is
                    incomplete/malformed (Feature #190). Warnings are added
                    to the response but processing continues.

        Returns:
            OctoResponse with generated specs, test contracts, or error information.
            In lenient mode, may include warnings about applied defaults.
        """
        # Step 1: Validate payload with detailed error information (Feature #190)
        validation_result = payload.validate_detailed(apply_defaults=lenient)

        if not validation_result.is_valid:
            # Build error message with remediation hints
            error_details = []
            for err in validation_result.errors:
                error_details.append(f"{err.field}: {err.message}")

            _logger.warning(
                "Invalid OctoRequestPayload: %s (hints: %s)",
                validation_result.error_messages,
                validation_result.remediation_hints,
            )

            return OctoResponse(
                success=False,
                error="Invalid request payload",
                error_type="validation_error",
                validation_errors=validation_result.error_messages,
                # Feature #190: Include remediation hints in warnings
                warnings=validation_result.remediation_hints,
                request_id=payload.request_id,
            )

        # Feature #190: Log defaults applied and add warnings
        if validation_result.defaults_applied:
            _logger.info(
                "Applied defaults for malformed payload fields: %s",
                list(validation_result.defaults_applied.keys()),
            )

        _logger.info(
            "Octo processing request: %d capabilities, %d existing agents",
            len(payload.required_capabilities),
            len(payload.existing_agents),
        )

        # Step 2: Generate specs for each capability
        generated_specs: list[AgentSpec] = []
        generated_contracts: list[TestContract] = []  # Feature #184
        warnings: list[str] = []

        # Feature #190: Include validation warnings about applied defaults
        if validation_result.warnings:
            for w in validation_result.warnings:
                warnings.append(f"[FIXED] {w.field}: {w.message}")

        # Track which specs were generated for which capability (for TestContract linking)
        spec_to_capability: dict[str, str] = {}

        for capability in payload.required_capabilities:
            # Skip if an agent with similar capability already exists
            if self._capability_covered(capability, payload.existing_agents):
                warnings.append(f"Capability '{capability}' covered by existing agent")
                continue

            # Build task description from capability
            task_desc = self._build_task_description(capability, payload)
            task_type = self._infer_task_type(capability)

            # Feature #187: Select appropriate model for this agent
            project_settings = payload.project_context.get("settings", {})
            selected_model = select_model_for_capability(
                capability=capability,
                task_type=task_type,
                constraints=payload.constraints,
                project_settings=project_settings,
            )

            # Invoke SpecBuilder
            _logger.info(
                "Generating spec for capability: %s (task_type=%s, model=%s)",
                capability, task_type, selected_model
            )

            try:
                result: BuildResult = self._builder.build(
                    task_description=task_desc,
                    task_type=task_type,
                    context={
                        "capability": capability,
                        "project_context": payload.project_context,
                        "octo_request_id": payload.request_id,
                        "model": selected_model,  # Feature #187: Include selected model
                    },
                )

                if result.success and result.agent_spec:
                    # Feature #187: Inject model into AgentSpec context
                    self._inject_model_into_spec(result.agent_spec, selected_model)

                    # Validate generated spec against schema
                    validation_result = self._validate_spec(result.agent_spec)

                    if validation_result.is_valid:
                        generated_specs.append(result.agent_spec)
                        spec_to_capability[result.agent_spec.name] = capability
                        _logger.info(
                            "Generated valid spec: %s (task_type=%s, model=%s)",
                            result.agent_spec.name,
                            result.agent_spec.task_type,
                            selected_model,
                        )
                    else:
                        warnings.append(
                            f"Spec for '{capability}' failed validation: {validation_result.errors}"
                        )
                        _logger.warning(
                            "Spec validation failed for %s: %s",
                            capability,
                            validation_result.errors,
                        )
                else:
                    warnings.append(
                        f"Failed to generate spec for '{capability}': {result.error}"
                    )
                    _logger.warning(
                        "SpecBuilder failed for %s: %s",
                        capability,
                        result.error,
                    )

            except Exception as e:
                warnings.append(f"Exception generating spec for '{capability}': {e}")
                _logger.exception("Exception during spec generation for %s", capability)

        # Step 3: Check if any specs were generated
        if not generated_specs:
            return OctoResponse(
                success=False,
                error="No valid specs generated",
                error_type="generation_failed",
                warnings=warnings,
                request_id=payload.request_id,
            )

        # Step 3.5 (Feature #185): Validate specs against constraints
        all_constraint_violations: list[ConstraintViolation] = []
        validated_specs: list[AgentSpec] = []

        # Create constraint validator from payload constraints
        constraint_validator = self._create_constraint_validator(payload)

        for spec in generated_specs:
            # Validate spec against constraints
            constraint_result = constraint_validator.validate(spec, auto_correct=True)

            if constraint_result.is_valid:
                # Spec passes all constraints (possibly after correction)
                final_spec = constraint_result.corrected_spec if constraint_result.corrected_spec else spec
                validated_specs.append(final_spec)
                _logger.info(
                    "Spec %s passed constraint validation (corrected=%s)",
                    spec.name,
                    constraint_result.corrected_spec is not None,
                )
            else:
                # Spec has uncorrectable constraint violations
                all_constraint_violations.extend(constraint_result.violations)
                warnings.append(
                    f"Spec '{spec.name}' rejected due to constraint violations: "
                    f"{[v.message for v in constraint_result.violations]}"
                )
                _logger.warning(
                    "Spec %s rejected due to %d constraint violations",
                    spec.name,
                    len(constraint_result.violations),
                )
                # Feature #185 Step 4: Log constraint violations for debugging
                for violation in constraint_result.violations:
                    _logger.debug(
                        "Constraint violation: spec=%s, type=%s, field=%s, message=%s",
                        spec.name,
                        violation.constraint_type,
                        violation.field,
                        violation.message,
                    )

        # Update generated_specs to use validated/corrected specs
        generated_specs = validated_specs

        # Check if we still have valid specs after constraint validation
        if not generated_specs:
            return OctoResponse(
                success=False,
                error="All specs rejected due to constraint violations",
                error_type="constraint_validation_failed",
                constraint_violations=all_constraint_violations,
                warnings=warnings,
                request_id=payload.request_id,
            )

        # Step 4 (Feature #184): Generate TestContracts for testable agents
        # Feature #188: Validate TestContracts against schema before adding
        for spec in generated_specs:
            capability = spec_to_capability.get(spec.name, "")
            contract = generate_test_contract(
                agent_spec=spec,
                capability=capability,
                project_context=payload.project_context,
            )
            if contract:
                # Feature #188: Validate TestContract against schema
                contract_validation = self._validate_test_contract(contract)
                if contract_validation.is_valid:
                    generated_contracts.append(contract)
                    _logger.info(
                        "Generated valid TestContract for agent %s: test_type=%s, assertions=%d",
                        spec.name,
                        contract.test_type,
                        len(contract.assertions),
                    )
                else:
                    warnings.append(
                        f"TestContract for '{spec.name}' failed validation: {contract_validation.error_messages[:2]}"
                    )
                    _logger.warning(
                        "TestContract validation failed for %s: %s",
                        spec.name,
                        contract_validation.error_messages[:3],
                    )

        # Step 5 (Feature #188): Final validation - ensure no invalid outputs propagate
        # Perform final schema validation on all outputs before returning
        try:
            spec_dicts = [spec.to_dict() for spec in generated_specs]
            contract_dicts = [c.to_dict() for c in generated_contracts]

            # Validate all outputs (this will catch any edge cases)
            validate_octo_outputs(
                spec_dicts,
                contract_dicts,
                raise_on_error=True,
            )
        except OctoSchemaValidationError as e:
            _logger.error(
                "Final validation failed for Octo outputs: %s",
                str(e),
            )
            return OctoResponse(
                success=False,
                error=f"Output validation failed: {str(e)}",
                error_type="schema_validation_error",
                validation_errors=e.result.error_messages,
                warnings=warnings,
                request_id=payload.request_id,
            )

        _logger.info(
            "Octo generated %d specs and %d test contracts for request %s (all validated)",
            len(generated_specs),
            len(generated_contracts),
            payload.request_id,
        )

        return OctoResponse(
            success=True,
            agent_specs=generated_specs,
            test_contracts=generated_contracts,
            constraint_violations=all_constraint_violations,  # Feature #185: Include any violations
            warnings=warnings,
            request_id=payload.request_id,
        )

    def _capability_covered(
        self,
        capability: str,
        existing_agents: list[str],
    ) -> bool:
        """
        Check if a capability is already covered by existing agents.

        Uses simple string matching for now. Can be made smarter with
        capability-to-agent mapping.
        """
        capability_lower = capability.lower()

        for agent in existing_agents:
            agent_lower = agent.lower()
            # Check for substring matches
            if capability_lower in agent_lower or agent_lower in capability_lower:
                return True
            # Check common mappings
            if (capability_lower == "coding" and "coder" in agent_lower):
                return True
            if (capability_lower == "testing" and "test" in agent_lower):
                return True

        return False

    def _build_task_description(
        self,
        capability: str,
        payload: OctoRequestPayload,
    ) -> str:
        """
        Build a natural language task description for DSPy from capability.
        """
        project_name = payload.project_context.get("name", "the project")
        tech_stack = payload.project_context.get("tech_stack", [])
        tech_str = ", ".join(tech_stack) if tech_stack else "various technologies"

        # Map common capabilities to descriptions
        capability_descriptions = {
            "ui_testing": f"Implement end-to-end UI testing for {project_name} using browser automation.",
            "api_testing": f"Implement API integration tests for {project_name}'s backend endpoints.",
            "e2e_testing": f"Implement comprehensive end-to-end tests for {project_name}.",
            "unit_testing": f"Implement unit tests for {project_name} components.",
            "documentation": f"Generate and maintain documentation for {project_name}.",
            "security_audit": f"Perform security audit and vulnerability scanning for {project_name}.",
            "code_review": f"Review code changes and enforce quality standards for {project_name}.",
            "refactoring": f"Identify and implement refactoring opportunities in {project_name}.",
            "deployment": f"Handle deployment and release processes for {project_name}.",
            "monitoring": f"Set up monitoring and alerting for {project_name}.",
        }

        base_desc = capability_descriptions.get(
            capability.lower(),
            f"Implement {capability} functionality for {project_name}."
        )

        return f"{base_desc} The project uses {tech_str}."

    def _infer_task_type(self, capability: str) -> str:
        """
        Infer task_type from capability name.
        """
        capability_lower = capability.lower()

        # Testing-related capabilities
        if any(kw in capability_lower for kw in ["test", "qa", "e2e", "integration"]):
            return "testing"

        # Documentation capabilities
        if any(kw in capability_lower for kw in ["doc", "readme", "wiki"]):
            return "documentation"

        # Audit/security capabilities
        if any(kw in capability_lower for kw in ["audit", "security", "scan", "review"]):
            return "audit"

        # Refactoring capabilities
        if any(kw in capability_lower for kw in ["refactor", "cleanup", "optimize"]):
            return "refactoring"

        # Default to coding
        return "coding"

    def _create_constraint_validator(
        self,
        payload: OctoRequestPayload,
    ) -> ConstraintValidator:
        """
        Create a ConstraintValidator from payload constraints.

        Feature #185, Step 1: Define constraints from payload

        Args:
            payload: The OctoRequestPayload containing constraints

        Returns:
            ConstraintValidator configured with appropriate constraints
        """
        # Create constraints from payload's constraints dict
        constraints = create_constraints_from_payload(
            constraints_dict=payload.constraints,
            project_context=payload.project_context,
        )

        # Create and return validator
        validator = ConstraintValidator(
            constraints=constraints,
            auto_correct=True,  # Attempt to auto-correct violations
            reject_on_uncorrectable=True,  # Reject specs with uncorrectable violations
        )

        _logger.debug(
            "Created ConstraintValidator with %d constraints for request %s",
            len(constraints),
            payload.request_id,
        )

        return validator

    def _validate_spec(self, spec: AgentSpec) -> SpecValidationResult:
        """
        Validate an AgentSpec against multiple validation layers.

        Feature #188: Octo outputs are strictly typed and schema-validated

        This method performs two-layer validation:
        1. SpecValidationResult from spec_validator (model-level validation)
        2. SchemaValidationResult from octo_schemas (JSON schema validation)

        Both layers must pass for the spec to be considered valid.
        """
        # Layer 1: Model-level validation (from spec_validator)
        model_result = validate_spec(spec)

        if not model_result.is_valid:
            _logger.warning(
                "AgentSpec %s failed model validation: %s",
                getattr(spec, "name", "unknown"),
                model_result.error_messages[:3],
            )
            return model_result

        # Layer 2: JSON schema validation (Feature #188)
        try:
            spec_dict = spec.to_dict()
            schema_result = validate_agent_spec_schema(spec_dict)

            if not schema_result.is_valid:
                _logger.warning(
                    "AgentSpec %s failed schema validation: %s",
                    spec.name,
                    schema_result.error_messages[:3],
                )
                # Convert schema errors to model validation format
                # This ensures consistent error format for callers
                from api.spec_validator import ValidationError
                converted_errors = [
                    ValidationError(
                        field=err.path,
                        message=err.message,
                        code=err.code,
                        value=err.value,
                    )
                    for err in schema_result.errors
                ]
                return SpecValidationResult(
                    is_valid=False,
                    errors=converted_errors,
                    spec_id=spec.id,
                    spec_name=spec.name,
                )

        except Exception as e:
            _logger.exception(
                "Exception during schema validation for %s: %s",
                getattr(spec, "name", "unknown"),
                e,
            )
            from api.spec_validator import ValidationError
            return SpecValidationResult(
                is_valid=False,
                errors=[ValidationError(
                    field="$",
                    message=f"Schema validation exception: {e}",
                    code="schema_exception",
                )],
                spec_id=getattr(spec, "id", None),
                spec_name=getattr(spec, "name", None),
            )

        _logger.debug(
            "AgentSpec %s passed all validation layers",
            spec.name,
        )
        return model_result

    def _validate_test_contract(self, contract: TestContract) -> SchemaValidationResult:
        """
        Validate a TestContract against the JSON schema.

        Feature #188: Octo outputs are strictly typed and schema-validated

        Args:
            contract: The TestContract to validate

        Returns:
            SchemaValidationResult with is_valid flag and any errors
        """
        try:
            # First validate using the contract's own validate method
            internal_errors = contract.validate()
            if internal_errors:
                _logger.warning(
                    "TestContract %s failed internal validation: %s",
                    contract.agent_name,
                    internal_errors[:3],
                )
                return SchemaValidationResult(
                    is_valid=False,
                    errors=[
                        SchemaValidationError(
                            path="$",
                            message=err,
                            code="internal_validation",
                        )
                        for err in internal_errors
                    ],
                    schema_name="TestContract",
                )

            # Then validate against JSON schema
            contract_dict = contract.to_dict()
            schema_result = validate_test_contract_schema(contract_dict)

            if not schema_result.is_valid:
                _logger.warning(
                    "TestContract %s failed schema validation: %s",
                    contract.agent_name,
                    schema_result.error_messages[:3],
                )

            return schema_result

        except Exception as e:
            _logger.exception(
                "Exception during TestContract validation for %s: %s",
                getattr(contract, "agent_name", "unknown"),
                e,
            )
            return SchemaValidationResult(
                is_valid=False,
                errors=[SchemaValidationError(
                    path="$",
                    message=f"Schema validation exception: {e}",
                    code="schema_exception",
                )],
                schema_name="TestContract",
            )

    def _inject_model_into_spec(
        self,
        spec: AgentSpec,
        model: str,
    ) -> None:
        """
        Inject the selected model into the AgentSpec's context.

        Feature #187: Octo selects appropriate model for each agent

        The model is stored in the spec's context field under the key 'model'.
        This allows downstream consumers (harness, executors) to use the
        appropriate Claude model for execution.

        Args:
            spec: The AgentSpec to modify
            model: The selected model name (sonnet, opus, haiku)
        """
        # Ensure context exists
        if spec.context is None:
            spec.context = {}

        # Store model in context
        spec.context["model"] = model

        # Also store model characteristics for downstream consumers
        characteristics = get_model_characteristics(model)
        spec.context["model_characteristics"] = {
            "complexity": characteristics["complexity"],
            "cost": characteristics["cost"],
            "speed": characteristics["speed"],
        }

        _logger.debug(
            "Injected model '%s' into AgentSpec '%s' context",
            model,
            spec.name,
        )

    def _create_constraint_validator(
        self,
        payload: OctoRequestPayload,
    ) -> ConstraintValidator:
        """
        Create a ConstraintValidator from the OctoRequestPayload.

        Feature #185: Octo DSPy module with constraint satisfaction

        This method creates constraints from the payload's constraints field
        and wraps them in a ConstraintValidator for spec validation.

        Args:
            payload: The OctoRequestPayload containing constraint definitions

        Returns:
            ConstraintValidator configured for the payload's constraints
        """
        # If payload has explicit constraints, use them
        if payload.constraints:
            constraints = create_constraints_from_payload(payload.constraints)
        else:
            # Use default constraints if none specified
            constraints = create_default_constraints()

        return ConstraintValidator(constraints)

    # -------------------------------------------------------------------------
    # Feature #189: AgentSpec Persistence
    # -------------------------------------------------------------------------

    def persist_spec(
        self,
        spec: AgentSpec,
        session: Session,
        *,
        project_name: str | None = None,
        octo_request_id: str | None = None,
        source_feature_ids: list[int] | None = None,
    ) -> SpecPersistenceResult:
        """
        Persist a single AgentSpec to the database.

        Feature #189: Octo persists AgentSpecs to database

        This method saves the AgentSpec to the agent_specs table with:
        - source_type='octo_generated' in the context field
        - Project name and request ID linkage in context
        - Source feature ID linkage if provided

        The database record is the system-of-record. Files materialized later
        are CLI-authoritative but secondary to the database.

        Args:
            spec: The AgentSpec to persist
            session: SQLAlchemy session for database operations
            project_name: Name of the project this spec belongs to
            octo_request_id: ID of the Octo request that generated this spec
            source_feature_ids: Feature IDs that triggered the spec generation

        Returns:
            SpecPersistenceResult indicating success or failure
        """
        try:
            # Step 2: Spec includes source_type='octo_generated'
            # Inject source metadata into context before persisting
            self._inject_source_metadata(
                spec=spec,
                source_type=SOURCE_TYPE_OCTO_GENERATED,
                project_name=project_name,
                octo_request_id=octo_request_id,
                source_feature_ids=source_feature_ids,
            )

            # Link to first source feature if provided
            if source_feature_ids and len(source_feature_ids) > 0:
                spec.source_feature_id = source_feature_ids[0]

            # Add spec to session and flush to get ID assigned
            session.add(spec)
            session.flush()

            _logger.info(
                "Persisted AgentSpec '%s' (id=%s) to database with source_type='%s'",
                spec.name,
                spec.id,
                SOURCE_TYPE_OCTO_GENERATED,
            )

            return SpecPersistenceResult(
                spec_id=spec.id,
                spec_name=spec.name,
                success=True,
                source_type=SOURCE_TYPE_OCTO_GENERATED,
                project_name=project_name,
                octo_request_id=octo_request_id,
            )

        except Exception as e:
            _logger.error(
                "Failed to persist AgentSpec '%s': %s",
                spec.name if spec else "unknown",
                e,
            )
            return SpecPersistenceResult(
                spec_id=spec.id if spec else "",
                spec_name=spec.name if spec else "",
                success=False,
                error=str(e),
                source_type=SOURCE_TYPE_OCTO_GENERATED,
                project_name=project_name,
                octo_request_id=octo_request_id,
            )

    def persist_specs(
        self,
        specs: list[AgentSpec],
        session: Session,
        *,
        project_name: str | None = None,
        octo_request_id: str | None = None,
        source_feature_ids: list[int] | None = None,
    ) -> list[SpecPersistenceResult]:
        """
        Persist multiple AgentSpecs to the database.

        Feature #189: Octo persists AgentSpecs to database

        This is a convenience method that persists multiple specs in a single
        transaction. All specs are saved or none are (atomic).

        Args:
            specs: List of AgentSpecs to persist
            session: SQLAlchemy session for database operations
            project_name: Name of the project these specs belong to
            octo_request_id: ID of the Octo request that generated these specs
            source_feature_ids: Feature IDs that triggered the spec generation

        Returns:
            List of SpecPersistenceResults for each spec
        """
        results: list[SpecPersistenceResult] = []

        for spec in specs:
            result = self.persist_spec(
                spec=spec,
                session=session,
                project_name=project_name,
                octo_request_id=octo_request_id,
                source_feature_ids=source_feature_ids,
            )
            results.append(result)

        succeeded = sum(1 for r in results if r.success)
        _logger.info(
            "Persisted %d/%d AgentSpecs for project '%s', request '%s'",
            succeeded,
            len(specs),
            project_name or "unknown",
            octo_request_id or "unknown",
        )

        return results

    def generate_and_persist_specs(
        self,
        payload: OctoRequestPayload,
        session: Session,
    ) -> tuple[OctoResponse, list[SpecPersistenceResult]]:
        """
        Generate AgentSpecs and persist them to the database.

        Feature #189 Step 4: Database record created before file materialization

        This method combines spec generation with database persistence, ensuring
        the DB record is created BEFORE any file materialization occurs. This
        implements the "dual persistence" model where:
        - Database is the system-of-record
        - Files are CLI-authoritative

        The workflow is:
        1. Generate specs via DSPy pipeline
        2. Persist specs to database (system-of-record)
        3. Return both OctoResponse and persistence results
        4. Caller can then proceed with file materialization

        Args:
            payload: OctoRequestPayload with project context and requirements
            session: SQLAlchemy session for database operations

        Returns:
            Tuple of (OctoResponse, list of SpecPersistenceResults)
        """
        # Step 1: Generate specs using existing generate_specs method
        response = self.generate_specs(payload)

        # If generation failed, return early with empty persistence results
        if not response.success or not response.agent_specs:
            _logger.warning(
                "Spec generation failed or no specs generated for request %s",
                payload.request_id,
            )
            return response, []

        # Step 2: Extract project name from context
        project_name = payload.project_context.get("name") or payload.project_context.get("project_name")

        # Step 3: Persist all generated specs to database BEFORE materialization
        _logger.info(
            "Persisting %d generated specs to database before materialization",
            len(response.agent_specs),
        )

        persistence_results = self.persist_specs(
            specs=response.agent_specs,
            session=session,
            project_name=project_name,
            octo_request_id=payload.request_id,
            source_feature_ids=payload.source_feature_ids,
        )

        # Log persistence summary
        succeeded = sum(1 for r in persistence_results if r.success)
        _logger.info(
            "Persisted %d/%d specs for request %s (project=%s)",
            succeeded,
            len(persistence_results),
            payload.request_id,
            project_name,
        )

        return response, persistence_results

    def _inject_source_metadata(
        self,
        spec: AgentSpec,
        source_type: str,
        project_name: str | None = None,
        octo_request_id: str | None = None,
        source_feature_ids: list[int] | None = None,
    ) -> None:
        """
        Inject source metadata into the AgentSpec's context.

        Feature #189 Step 2 & 3: Spec includes source_type and project linkage

        This ensures every spec persisted by Octo has proper provenance tracking:
        - source_type: How the spec was created (octo_generated)
        - project_name: Which project this spec belongs to
        - octo_request_id: Which Octo request generated this spec
        - source_feature_ids: Which features triggered generation

        Args:
            spec: The AgentSpec to modify
            source_type: The source type to record
            project_name: Name of the project
            octo_request_id: ID of the triggering Octo request
            source_feature_ids: Feature IDs that triggered generation
        """
        # Ensure context exists
        if spec.context is None:
            spec.context = {}

        # Step 2: Include source_type='octo_generated'
        spec.context["source_type"] = source_type

        # Step 3: Link to project and triggering request
        if project_name:
            spec.context["project_name"] = project_name

        if octo_request_id:
            spec.context["octo_request_id"] = octo_request_id

        if source_feature_ids:
            spec.context["source_feature_ids"] = source_feature_ids

        _logger.debug(
            "Injected source metadata into AgentSpec '%s': source_type=%s, project=%s, request=%s",
            spec.name,
            source_type,
            project_name,
            octo_request_id,
        )


# =============================================================================
# Module-level convenience functions
# =============================================================================

_default_octo: Octo | None = None


def get_octo(api_key: str | None = None) -> Octo:
    """
    Get or create the default Octo instance.

    Args:
        api_key: Optional API key override

    Returns:
        Octo service instance
    """
    global _default_octo

    if _default_octo is None or api_key is not None:
        _default_octo = Octo(api_key=api_key)

    return _default_octo


def reset_octo() -> None:
    """Reset the default Octo instance (for testing)."""
    global _default_octo
    _default_octo = None
